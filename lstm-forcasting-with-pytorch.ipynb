{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3068590,"sourceType":"datasetVersion","datasetId":1870816}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-21T17:21:46.07595Z","iopub.execute_input":"2023-08-21T17:21:46.076392Z","iopub.status.idle":"2023-08-21T17:21:46.094335Z","shell.execute_reply.started":"2023-08-21T17:21:46.076337Z","shell.execute_reply":"2023-08-21T17:21:46.093115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I could not download the CPCB data so I am implmenting LSTM forecasting on this Kaggle dataset**","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/lstm-datasets-multivariate-univariate/LSTM-Multivariate_pollution.csv\").drop(columns=[\"date\"])\n\nprint(df_train.shape)\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:46.096994Z","iopub.execute_input":"2023-08-21T17:21:46.09748Z","iopub.status.idle":"2023-08-21T17:21:46.215883Z","shell.execute_reply.started":"2023-08-21T17:21:46.097436Z","shell.execute_reply":"2023-08-21T17:21:46.214453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/lstm-datasets-multivariate-univariate/pollution_test_data1.csv\")\n\nprint(df_test.shape)\n\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:46.21884Z","iopub.execute_input":"2023-08-21T17:21:46.21932Z","iopub.status.idle":"2023-08-21T17:21:46.243491Z","shell.execute_reply.started":"2023-08-21T17:21:46.219276Z","shell.execute_reply":"2023-08-21T17:21:46.242296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking null values\nprint(df_train.isnull().sum() , \"\\n -------- \\n\" , df_test.isnull().sum() )","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:46.245138Z","iopub.execute_input":"2023-08-21T17:21:46.246398Z","iopub.status.idle":"2023-08-21T17:21:46.272758Z","shell.execute_reply.started":"2023-08-21T17:21:46.246337Z","shell.execute_reply":"2023-08-21T17:21:46.271447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Create a subplot for each variable\nfig = make_subplots(rows=4, cols=2, subplot_titles=('Pollution', 'Dew', 'Temperature', 'Pressure', 'Wind Direction', 'Wind Speed', 'Snow', 'Rain'))\n\n# Define color palette\ncolors = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880']\n\n# Add a histogram for each variable\nfig.add_trace(go.Histogram(x=df_train['pollution'], nbinsx=20, marker_color=colors[0]), row=1, col=1)\nfig.add_trace(go.Histogram(x=df_train['dew'], nbinsx=20, marker_color=colors[1]), row=1, col=2)\nfig.add_trace(go.Histogram(x=df_train['temp'], nbinsx=20, marker_color=colors[2]), row=2, col=1)\nfig.add_trace(go.Histogram(x=df_train['press'], nbinsx=20, marker_color=colors[3]), row=2, col=2)\nfig.add_trace(go.Histogram(x=df_train['wnd_dir'], nbinsx=20, marker_color=colors[4]), row=3, col=1)\nfig.add_trace(go.Histogram(x=df_train['wnd_spd'], nbinsx=20, marker_color=colors[5]), row=3, col=2)\nfig.add_trace(go.Histogram(x=df_train['snow'], nbinsx=20, marker_color=colors[6]), row=4, col=1)\nfig.add_trace(go.Histogram(x=df_train['rain'], nbinsx=20, marker_color=colors[7]), row=4, col=2)\n\n# Update layout\nfig.update_layout(height=1000, width=1200, title_text='Distribution of Variables', showlegend=False)\n\n# Customize axis labels and titles\nfig.update_xaxes(title_text='Value', row=1, col=1)\nfig.update_xaxes(title_text='Value', row=1, col=2)\nfig.update_xaxes(title_text='Value', row=2, col=1)\nfig.update_xaxes(title_text='Value', row=2, col=2)\nfig.update_xaxes(title_text='Value', row=3, col=1)\nfig.update_xaxes(title_text='Value', row=3, col=2)\nfig.update_xaxes(title_text='Value', row=4, col=1)\nfig.update_xaxes(title_text='Value', row=4, col=2)\n\nfig.update_yaxes(title_text='Frequency', row=1, col=1)\nfig.update_yaxes(title_text='Frequency', row=1, col=2)\nfig.update_yaxes(title_text='Frequency', row=2, col=1)\nfig.update_yaxes(title_text='Frequency', row=2, col=2)\nfig.update_yaxes(title_text='Frequency', row=3, col=1)\nfig.update_yaxes(title_text='Frequency', row=3, col=2)\nfig.update_yaxes(title_text='Frequency', row=4, col=1)\nfig.update_yaxes(title_text='Frequency', row=4, col=2)\n\n# Customize subplot titles\nfig.update_annotations(font_size=16)\n\n# Show the plot\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:46.277023Z","iopub.execute_input":"2023-08-21T17:21:46.277452Z","iopub.status.idle":"2023-08-21T17:21:46.697047Z","shell.execute_reply.started":"2023-08-21T17:21:46.277412Z","shell.execute_reply":"2023-08-21T17:21:46.695627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nvalues = df_train.values\n\n# specify columns to plot\ngroups = [1, 2, 3]\ni = 1\n\n# plot each column\nfig, axs = plt.subplots(len(groups), 1, figsize=(20, 14), facecolor='white')\nfor group, ax in zip(groups, axs):\n    ax.plot(values[:, group], color=cm.viridis(group/len(groups)))\n    ax.set_title(df_train.columns[group], y=0.75, loc='right', fontsize=20)\n    ax.tick_params(axis='both', which='major', labelsize=14)\n    ax.grid(True)\n    i += 1\n\nplt.suptitle('Time Series Plot of Selected Variables', fontsize=24)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:46.698426Z","iopub.execute_input":"2023-08-21T17:21:46.698792Z","iopub.status.idle":"2023-08-21T17:21:48.035877Z","shell.execute_reply.started":"2023-08-21T17:21:46.698759Z","shell.execute_reply":"2023-08-21T17:21:48.03485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_scaled = df_train.copy()\ndf_test_scaled = df_test.copy()\n\n# Define the mapping dictionary\nmapping = {'NE': 0, 'SE': 1, 'NW': 2, 'cv': 3}\n\n# Replace the string values with numerical values\ndf_train_scaled['wnd_dir'] = df_train_scaled['wnd_dir'].map(mapping)\ndf_test_scaled['wnd_dir'] = df_test_scaled['wnd_dir'].map(mapping)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:48.037451Z","iopub.execute_input":"2023-08-21T17:21:48.038656Z","iopub.status.idle":"2023-08-21T17:21:48.058797Z","shell.execute_reply.started":"2023-08-21T17:21:48.038616Z","shell.execute_reply":"2023-08-21T17:21:48.057642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Create a scaler object\nscaler = MinMaxScaler()\n\n\n# Define the columns to scale\ncolumns = (['pollution', 'dew', 'temp', 'press', 'wnd_spd',\n       'snow', 'rain' , \"wnd_dir\"])\n\n\n# Scale the selected columns to the range 0-1\ndf_train_scaled[columns] = scaler.fit_transform(df_train_scaled[columns])\ndf_test_scaled[columns] = scaler.transform(df_test_scaled[columns])\n\n\n# Show the scaled data\ndf_train_scaled.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:48.060698Z","iopub.execute_input":"2023-08-21T17:21:48.061473Z","iopub.status.idle":"2023-08-21T17:21:48.572824Z","shell.execute_reply.started":"2023-08-21T17:21:48.061436Z","shell.execute_reply":"2023-08-21T17:21:48.571448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the window size\nwindow_size = 10\n\n#-------------------------TrainSet---------------------------------\n\n# Initialize empty lists to store X and Y\nX_sequences = []\nY_values = []\n\n# Iterate through the DataFrame to create sequences\nfor i in range(len(df_train_scaled) - window_size):\n    X_seq = df_train_scaled.iloc[i:i+window_size].values\n    Y_val = df_train_scaled.iloc[i+window_size]['pollution']\n    X_sequences.append(X_seq)\n    Y_values.append(Y_val)\n\n# Convert the lists to NumPy arrays for modeling\nX_train = np.array(X_sequences)\ny_train = np.array(Y_values)\n\n#-------------------------TestSet---------------------------------\n\n# Initialize empty lists to store X and Y\nX_sequences = []\nY_values = []\n\n# Iterate through the DataFrame to create sequences\nfor i in range(len(df_test_scaled) - window_size):\n    X_seq = df_test_scaled.iloc[i:i+window_size].values\n    Y_val = df_test_scaled.iloc[i+window_size]['pollution']\n    X_sequences.append(X_seq)\n    Y_values.append(Y_val)\n\n# Convert the lists to NumPy arrays for modeling\nX_test = np.array(X_sequences)\ny_test = np.array(Y_values)\n\n#-----------------------------------------------------------------\nprint(\"Train size : \" , X_train.shape , y_train.shape,\"\\n ------- \\n\"\n      \"Test Size : \",X_test.shape , y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:21:48.577857Z","iopub.execute_input":"2023-08-21T17:21:48.579101Z","iopub.status.idle":"2023-08-21T17:22:02.108122Z","shell.execute_reply.started":"2023-08-21T17:21:48.579057Z","shell.execute_reply":"2023-08-21T17:22:02.106778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nX_train = torch.from_numpy(X_train.astype(np.float32))\nX_test = torch.from_numpy(X_test.astype(np.float32))\ny_train = torch.from_numpy(y_train.astype(np.float32).reshape(-1,1))\ny_test = torch.from_numpy(y_test.astype(np.float32).reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:22:02.109976Z","iopub.execute_input":"2023-08-21T17:22:02.110499Z","iopub.status.idle":"2023-08-21T17:22:03.771524Z","shell.execute_reply.started":"2023-08-21T17:22:02.110458Z","shell.execute_reply":"2023-08-21T17:22:03.770355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define LSTM Model\n\nclass LSTM(nn.Module):\n    def __init__(self , input_size , hidden_size , num_layers , output_size):\n        super(LSTM , self).__init__()\n        self.input = input_size\n        self.output = output_size\n        self.H = hidden_size\n        self.L = num_layers\n        \n        self.LSTM = nn.LSTM(input_size = self.input , hidden_size  = self.H , \n                            num_layers = self.L , batch_first = True)\n        \n        self.fc   = nn.Linear(self.H , self.output)\n        \n    def forward(self , x):\n        # Initialize hidden states for each layer and batch\n        h0 = torch.zeros(self.L , x.size(0) , self.H ).to(device)\n        c0 = torch.zeros(self.L , x.size(0) , self.H ).to(device)\n        \n        # Forward Pass\n        out , _ = self.LSTM(x , (h0,c0))\n    \n        out = self.fc(out[:, -1, :])\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:22:03.773056Z","iopub.execute_input":"2023-08-21T17:22:03.774347Z","iopub.status.idle":"2023-08-21T17:22:03.785342Z","shell.execute_reply.started":"2023-08-21T17:22:03.774302Z","shell.execute_reply":"2023-08-21T17:22:03.784062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:22:03.787249Z","iopub.execute_input":"2023-08-21T17:22:03.787698Z","iopub.status.idle":"2023-08-21T17:22:03.829107Z","shell.execute_reply.started":"2023-08-21T17:22:03.787658Z","shell.execute_reply":"2023-08-21T17:22:03.827834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_layer = 16\nhidden_size = 32\ninput_size = 10\noutput_size = 1\n\nmodel = LSTM(input_size = input_size , hidden_size= hidden_size,\n num_layers = num_layer, output_size = output_size).to(device)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.MSELoss()\n\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:22:03.83148Z","iopub.execute_input":"2023-08-21T17:22:03.832391Z","iopub.status.idle":"2023-08-21T17:22:06.116917Z","shell.execute_reply.started":"2023-08-21T17:22:03.832289Z","shell.execute_reply":"2023-08-21T17:22:06.115555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\n# Define batch size\nbatch_size = 128\n\n# Define data loaders for training and testing data in batches\ntrain_data = TensorDataset(X_train, y_train)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n\ntest_data = TensorDataset(X_test, y_test)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:22:06.118578Z","iopub.execute_input":"2023-08-21T17:22:06.119207Z","iopub.status.idle":"2023-08-21T17:22:06.127175Z","shell.execute_reply.started":"2023-08-21T17:22:06.119165Z","shell.execute_reply":"2023-08-21T17:22:06.126084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\n\ntrain_losses = []  # To store train losses\ntest_losses = []   # To store test losses\n\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    train_loss = 0.0\n    \n    for i, (inputs, targets) in enumerate(train_loader):\n        # Forward pass\n        inputs = inputs.reshape(-1, 8, 10).to(device)\n        targets = targets.reshape(-1, 1).to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        # Backward and optimize\n        loss.backward()\n        optimizer.step()\n\n        # Accumulate train loss\n        train_loss += loss.item()\n\n    # Calculate and store the average train loss for this epoch\n    avg_train_loss = train_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}\")\n\n    # Validation (testing) after each epoch\n    model.eval()  # Set the model to evaluation mode\n    test_loss = 0.0\n    \n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs = inputs.reshape(-1, 8, 10).to(device)\n            targets = targets.reshape(-1, 1).to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # Accumulate test loss\n            test_loss += loss.item()\n\n    # Calculate and store the average test loss for this epoch\n    avg_test_loss = test_loss / len(test_loader)\n    test_losses.append(avg_test_loss)\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Test Loss: {avg_test_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:22:06.128662Z","iopub.execute_input":"2023-08-21T17:22:06.129678Z","iopub.status.idle":"2023-08-21T17:25:56.57188Z","shell.execute_reply.started":"2023-08-21T17:22:06.129636Z","shell.execute_reply":"2023-08-21T17:25:56.570397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    predicted_values = model(X_test.reshape(-1, 8, 10).to(device)).cpu().numpy()\n\n# Create a scatter plot of true values vs. predicted values\nplt.figure(figsize=(6, 6))\nplt.plot(df_test_scaled[\"pollution\"]  , label='True Values',color='blue')\nplt.plot(predicted_values , label='Predicted Values', color='red')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:26:01.132155Z","iopub.execute_input":"2023-08-21T17:26:01.132551Z","iopub.status.idle":"2023-08-21T17:26:01.538881Z","shell.execute_reply.started":"2023-08-21T17:26:01.13252Z","shell.execute_reply":"2023-08-21T17:26:01.537752Z"},"trusted":true},"execution_count":null,"outputs":[]}]}